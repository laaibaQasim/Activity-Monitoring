{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**GROUP MEMBERS:**\n",
        "\n",
        "BCSF20M001  Munazza Shahzad Mughal\n",
        "\n",
        "BCSF20M013  Hafiza Laiba Qasim\n",
        "\n",
        "BCSF20M028  Ayesha Arshad\n",
        "\n",
        "BCSF20M038  Tooba Atif\n",
        "\n",
        "BCSF20M061  Fatima Habib"
      ],
      "metadata": {
        "id": "DsjjNslZ0UZd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0Wa51UbjOpkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890c014d-526c-48f7-a7da-502e7ff528fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "Bk9BpUd0SPJs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/ML_Project/\""
      ],
      "metadata": {
        "id": "6_RMm70qSQON"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Training Data"
      ],
      "metadata": {
        "id": "9t5cnW_ommts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load training data\n",
        "train_Acc= np.load(path + \"training/\" + \"trainAccelerometer.npy\")\n",
        "train_Grav= np.load(path + \"training/\" + \"trainGravity.npy\")\n",
        "train_Gyro= np.load(path + \"training/\" + \"trainMSGyroscope.npy\")\n",
        "train_JinAcc= np.load(path + \"training/\" + \"trainJinsAccelerometer.npy\")\n",
        "train_JinGyro= np.load(path + \"training/\" + \"trainJinsGyroscope.npy\")\n",
        "train_LintAcc= np.load(path + \"training/\" + \"trainLinearAcceleration.npy\")\n",
        "train_Magn= np.load(path + \"training/\" + \"trainMagnetometer.npy\")\n",
        "train_MSAcc= np.load(path + \"training/\" + \"trainMSAccelerometer.npy\")\n",
        "train_MSGyro= np.load(path + \"training/\" + \"trainMSGyroscope.npy\")\n",
        "\n",
        "# shapes\n",
        "print(train_Acc.shape)\n",
        "print(train_Grav.shape)\n",
        "print(train_Gyro.shape)\n",
        "print(train_JinAcc.shape)\n",
        "print(train_JinGyro.shape)\n",
        "print(train_LintAcc.shape)\n",
        "print(train_Magn.shape)\n",
        "print(train_MSAcc.shape)\n",
        "print(train_MSGyro.shape)\n",
        "\n",
        "# load training labels\n",
        "train_Labels= np.load(path + \"training/\" + \"trainLabels.npy\")\n",
        "print(train_Labels.shape)"
      ],
      "metadata": {
        "id": "Fg07HHnLUJzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983875b7-84bf-4a4a-fdb4-bbc2f97c9456"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2284, 800, 3)\n",
            "(2284, 800, 3)\n",
            "(2284, 268, 3)\n",
            "(2284, 80, 3)\n",
            "(2284, 80, 3)\n",
            "(2284, 800, 3)\n",
            "(2284, 200, 3)\n",
            "(2284, 268, 3)\n",
            "(2284, 268, 3)\n",
            "(2284,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Test Data"
      ],
      "metadata": {
        "id": "aLzp6614mhWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load test data\n",
        "test_Acc= np.load(path + \"testing/\" + \"testAccelerometer.npy\")\n",
        "test_Grav= np.load(path + \"testing/\" + \"testGravity.npy\")\n",
        "test_Gyro= np.load(path + \"testing/\" + \"testGyroscope.npy\")\n",
        "test_JinAcc= np.load(path + \"testing/\" + \"testJinsAccelerometer.npy\")\n",
        "test_JinGyro= np.load(path + \"testing/\" + \"testJinsGyroscope.npy\")\n",
        "test_LintAcc= np.load(path + \"testing/\" + \"testLinearAcceleration.npy\")\n",
        "test_Magn= np.load(path + \"testing/\" + \"testMagnetometer.npy\")\n",
        "test_MSAcc= np.load(path + \"testing/\" + \"testMSAccelerometer.npy\")\n",
        "test_MSGyro= np.load(path + \"testing/\" + \"testMSGyroscope.npy\")\n",
        "\n",
        "# print shapes\n",
        "print(test_Acc.shape)\n",
        "print(test_Grav.shape)\n",
        "print(test_Gyro.shape)\n",
        "print(test_JinAcc.shape)\n",
        "print(test_JinGyro.shape)\n",
        "print(test_LintAcc.shape)\n",
        "print(test_Magn.shape)\n",
        "print(test_MSAcc.shape)\n",
        "print(test_MSGyro.shape)\n",
        "\n",
        "# load test labels\n",
        "test_Labels= np.load(path + \"testing/\" + \"testLabels.npy\")\n",
        "print(test_Labels.shape)"
      ],
      "metadata": {
        "id": "yYWVN-ObeJYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abf6d99-7131-4bfe-c5b5-fcfb111f86f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2288, 800, 3)\n",
            "(2288, 800, 3)\n",
            "(2288, 800, 3)\n",
            "(2288, 80, 3)\n",
            "(2288, 80, 3)\n",
            "(2288, 800, 3)\n",
            "(2288, 200, 3)\n",
            "(2288, 268, 3)\n",
            "(2288, 268, 3)\n",
            "(2288,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalizing train data**"
      ],
      "metadata": {
        "id": "nsd9HnaffzRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalizing the train_Acc\n",
        "reshaped_Acc = train_Acc.reshape(-1, train_Acc.shape[1])\n",
        "normalized_Acc = scaler.fit_transform(reshaped_Acc)\n",
        "normalized_Acc_train = normalized_Acc.reshape(train_Acc.shape)\n",
        "\n",
        "# Normalizing the train_Grav\n",
        "reshaped_Grav = train_Grav.reshape(-1, train_Grav.shape[1])\n",
        "normalized_Grav = scaler.fit_transform(reshaped_Grav)\n",
        "normalized_Grav_train = normalized_Grav.reshape(train_Grav.shape)\n",
        "\n",
        "# Normalizing the train_Gyro\n",
        "reshaped_Gyro = train_Gyro.reshape(-1, train_Gyro.shape[1])\n",
        "normalized_Gyro = scaler.fit_transform(reshaped_Gyro)\n",
        "normalized_Gyro_train = normalized_Gyro.reshape(train_Gyro.shape)\n",
        "\n",
        "# Normalizing the train_JinAcc\n",
        "reshaped_JinAcc = train_JinAcc.reshape(-1, train_JinAcc.shape[1])\n",
        "normalized_JinAcc = scaler.fit_transform(reshaped_JinAcc)\n",
        "normalized_JinAc_train = normalized_JinAcc.reshape(train_JinAcc.shape)\n",
        "\n",
        "# Normalizing the train_JinGyro\n",
        "reshaped_JinGyro = train_JinGyro.reshape(-1, train_JinGyro.shape[1])\n",
        "normalized_JinGyro = scaler.fit_transform(reshaped_JinGyro)\n",
        "normalized_JinGyro_train = normalized_JinGyro.reshape(train_JinGyro.shape)\n",
        "\n",
        "# Normalizing the train_LintAcc\n",
        "reshaped_LintAcc = train_LintAcc.reshape(-1, train_LintAcc.shape[1])\n",
        "normalized_LintAcc = scaler.fit_transform(reshaped_LintAcc)\n",
        "normalized_LintAcc_train = normalized_LintAcc.reshape(train_LintAcc.shape)\n",
        "\n",
        "# Normalizing the train_Magn\n",
        "reshaped_Magn = train_Magn.reshape(-1, train_Magn.shape[1])\n",
        "normalized_Magn = scaler.fit_transform(reshaped_Magn)\n",
        "normalized_Magn_train = normalized_Magn.reshape(train_Magn.shape)\n",
        "\n",
        "# Normalizing the train_MSAcc\n",
        "reshaped_MSAcc = train_MSAcc.reshape(-1, train_MSAcc.shape[1])\n",
        "print(\"Before Normalization train_MSAcc\",np.max(reshaped_MSAcc))\n",
        "normalized_MSAcc = scaler.fit_transform(reshaped_MSAcc)\n",
        "print(\"After Normalization normalized_MSAcc\",np.max(normalized_MSAcc))\n",
        "normalized_MSAcc_train = normalized_MSAcc.reshape(train_MSAcc.shape)\n",
        "\n",
        "# Normalizing the train_MSGyro\n",
        "reshaped_MSGyro = train_MSGyro.reshape(-1, train_MSGyro.shape[1])\n",
        "normalized_MSGyro = scaler.fit_transform(reshaped_MSGyro)\n",
        "normalized_MSGyro_train = normalized_MSGyro.reshape(train_MSGyro.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb91ZqV2e7r6",
        "outputId": "b5bbca2a-7213-4b2e-c171-fb22687b002d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Normalization train_MSAcc 7.9990234\n",
            "After Normalization normalized_MSAcc 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing test data"
      ],
      "metadata": {
        "id": "OfmtdNRo5zvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the test_Acc\n",
        "reshaped_Acc = test_Acc.reshape(-1, test_Acc.shape[1])\n",
        "normalized_Acc = scaler.fit_transform(reshaped_Acc)\n",
        "normalized_Acc_test = normalized_Acc.reshape(test_Acc.shape)\n",
        "\n",
        "# Normalizing the test_Grav\n",
        "reshaped_Grav = test_Grav.reshape(-1, test_Grav.shape[1])\n",
        "normalized_Grav = scaler.fit_transform(reshaped_Grav)\n",
        "normalized_Grav_test = normalized_Grav.reshape(test_Grav.shape)\n",
        "\n",
        "# Normalizing the test_Gyro\n",
        "reshaped_Gyro = test_Gyro.reshape(-1, test_Gyro.shape[1])\n",
        "normalized_Gyro = scaler.fit_transform(reshaped_Gyro)\n",
        "normalized_Gyro_test = normalized_Gyro.reshape(test_Gyro.shape)\n",
        "\n",
        "# Normalizing the test_JinAcc\n",
        "reshaped_JinAcc = test_JinAcc.reshape(-1, test_JinAcc.shape[1])\n",
        "normalized_JinAcc = scaler.fit_transform(reshaped_JinAcc)\n",
        "normalized_JinAcc_test = normalized_JinAcc.reshape(test_JinAcc.shape)\n",
        "\n",
        "# Normalizing the test_JinGyro\n",
        "reshaped_JinGyro = test_JinGyro.reshape(-1, test_JinGyro.shape[1])\n",
        "normalized_JinGyro = scaler.fit_transform(reshaped_JinGyro)\n",
        "normalized_JinGyro_test = normalized_JinGyro.reshape(test_JinGyro.shape)\n",
        "\n",
        "# Normalizing the test_LintAcc\n",
        "reshaped_LintAcc = test_LintAcc.reshape(-1, test_LintAcc.shape[1])\n",
        "normalized_LintAcc = scaler.fit_transform(reshaped_LintAcc)\n",
        "normalized_LintAcc_test = normalized_LintAcc.reshape(test_LintAcc.shape)\n",
        "\n",
        "# Normalizing the test_Magn\n",
        "reshaped_Magn = test_Magn.reshape(-1, test_Magn.shape[1])\n",
        "normalized_Magn = scaler.fit_transform(reshaped_Magn)\n",
        "normalized_Magn_test = normalized_Magn.reshape(test_Magn.shape)\n",
        "\n",
        "# Normalizing the test_MSAcc\n",
        "reshaped_MSAcc = test_MSAcc.reshape(-1, test_MSAcc.shape[1])\n",
        "print(\"Before Normalization test_MSAcc\",np.max(reshaped_MSAcc))\n",
        "normalized_MSAcc = scaler.fit_transform(reshaped_MSAcc)\n",
        "print(\"After Normalization normalized_MSAcc\",np.max(normalized_MSAcc))\n",
        "normalized_MSAcc_test = normalized_MSAcc.reshape(test_MSAcc.shape)\n",
        "\n",
        "# Normalizing the test_MSGyro\n",
        "reshaped_MSGyro = test_MSGyro.reshape(-1, test_MSGyro.shape[1])\n",
        "normalized_MSGyro = scaler.fit_transform(reshaped_MSGyro)\n",
        "normalized_MSGyro_test = normalized_MSGyro.reshape(test_MSGyro.shape)\n"
      ],
      "metadata": {
        "id": "BkbwNAWe55Ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8b695c-bf6a-403e-9d47-b9a9ca625d35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Normalization test_MSAcc 7.9990234\n",
            "After Normalization normalized_MSAcc 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Features training and testing"
      ],
      "metadata": {
        "id": "b2bRJZ_FmzEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numof_features=6\n",
        "training_Examples = np.shape(train_Labels)[0]\n",
        "testing_Examples = np.shape(test_Labels)[0]"
      ],
      "metadata": {
        "id": "gxhyZmebskIw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_features_Acc = np.zeros((training_Examples, numof_features, 3))\n",
        "train_features_Acc[:, 0, :] = np.mean(normalized_Acc_train, axis=1)\n",
        "train_features_Acc[:, 1, :] = np.max(normalized_Acc_train, axis=1)\n",
        "train_features_Acc[:, 2, :] = np.min(normalized_Acc_train, axis=1)\n",
        "train_features_Acc[:, 3, :] = np.sqrt(np.mean(normalized_Acc_train**2, axis=1))\n",
        "train_features_Acc[:, 4, :] = np.sum(np.diff(np.sign(normalized_Acc_train), axis=1) != 0, axis=1)\n",
        "train_features_Acc[:, 5, :] = np.std(normalized_Acc_train, axis=1)\n",
        "\n",
        "print(train_features_Acc.shape)\n",
        "\n",
        "# test\n",
        "test_features_Acc = np.zeros((testing_Examples, numof_features, 3))\n",
        "test_features_Acc[:, 0, :] = np.mean(normalized_Acc_test, axis=1)\n",
        "test_features_Acc[:, 1, :] = np.max(normalized_Acc_test, axis=1)\n",
        "test_features_Acc[:, 2, :] = np.min(normalized_Acc_test, axis=1)\n",
        "test_features_Acc[:, 3, :] = np.sqrt(np.mean(normalized_Acc_test**2, axis=1))\n",
        "test_features_Acc[:, 4, :] = np.sum(np.diff(np.sign(normalized_Acc_test), axis=1) != 0, axis=1)\n",
        "test_features_Acc[:, 5, :] = np.std(normalized_Acc_test, axis=1)\n",
        "\n",
        "print(test_features_Acc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHwRDPZ7m22M",
        "outputId": "207006de-382b-4b96-ae52-ecbaa666e73c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2284, 6, 3)\n",
            "(2288, 6, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_features_Grav = np.zeros((training_Examples, numof_features, train_Grav.shape[2]))\n",
        "\n",
        "# Calculate features for train_Grav\n",
        "train_features_Grav[:, 0, :] = np.mean(normalized_Grav_train, axis=1)\n",
        "train_features_Grav[:, 1, :] = np.max(normalized_Grav_train, axis=1)\n",
        "train_features_Grav[:, 2, :] = np.min(normalized_Grav_train, axis=1)\n",
        "train_features_Grav[:, 3, :] = np.sqrt(np.mean(normalized_Grav_train**2, axis=1))\n",
        "train_features_Grav[:, 4, :] = np.sum(np.diff(np.sign(normalized_Grav_train), axis=1) != 0, axis=1)\n",
        "train_features_Grav[:, 5, :] = np.std(normalized_Grav_train, axis=1)\n",
        "\n",
        "# test\n",
        "test_features_Grav = np.zeros((testing_Examples, numof_features, test_Grav.shape[2]))\n",
        "\n",
        "# Calculate features for test_Grav\n",
        "test_features_Grav[:, 0, :] = np.mean(normalized_Grav_test, axis=1)\n",
        "test_features_Grav[:, 1, :] = np.max(normalized_Grav_test, axis=1)\n",
        "test_features_Grav[:, 2, :] = np.min(normalized_Grav_test, axis=1)\n",
        "test_features_Grav[:, 3, :] = np.sqrt(np.mean(normalized_Grav_test**2, axis=1))\n",
        "test_features_Grav[:, 4, :] = np.sum(np.diff(np.sign(normalized_Grav_test), axis=1) != 0, axis=1)\n",
        "test_features_Grav[:, 5, :] = np.std(normalized_Grav_test, axis=1)\n"
      ],
      "metadata": {
        "id": "UIfjnEyIsbvv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_features_Gyro = np.zeros((training_Examples, numof_features, train_Gyro.shape[2]))\n",
        "\n",
        "# Calculate features for train_Gyro\n",
        "train_features_Gyro[:, 0, :] = np.mean(normalized_Gyro_train, axis=1)\n",
        "train_features_Gyro[:, 1, :] = np.max(normalized_Gyro_train, axis=1)\n",
        "train_features_Gyro[:, 2, :] = np.min(normalized_Gyro_train, axis=1)\n",
        "train_features_Gyro[:, 3, :] = np.sqrt(np.mean(normalized_Gyro_train**2, axis=1))\n",
        "train_features_Gyro[:, 4, :] = np.sum(np.diff(np.sign(normalized_Gyro_train), axis=1) != 0, axis=1)\n",
        "train_features_Gyro[:, 5, :] = np.std(normalized_Gyro_train, axis=1)\n",
        "\n",
        "# test\n",
        "test_features_Gyro = np.zeros((testing_Examples, numof_features, test_Gyro.shape[2]))\n",
        "\n",
        "# Calculate features for test_Gyro\n",
        "test_features_Gyro[:, 0, :] = np.mean(normalized_Gyro_test, axis=1)\n",
        "test_features_Gyro[:, 1, :] = np.max(normalized_Gyro_test, axis=1)\n",
        "test_features_Gyro[:, 2, :] = np.min(normalized_Gyro_test, axis=1)\n",
        "test_features_Gyro[:, 3, :] = np.sqrt(np.mean(normalized_Gyro_test**2, axis=1))\n",
        "test_features_Gyro[:, 4, :] = np.sum(np.diff(np.sign(normalized_Gyro_test), axis=1) != 0, axis=1)\n",
        "test_features_Gyro[:, 5, :] = np.std(normalized_Gyro_test, axis=1)\n"
      ],
      "metadata": {
        "id": "m9Wc9WDWuxxn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_features_JinAcc = np.zeros((training_Examples, numof_features, train_JinAcc.shape[2]))\n",
        "\n",
        "# Calculate features for train_JinAcc\n",
        "train_features_JinAcc[:, 0, :] = np.mean(normalized_JinAc_train, axis=1)\n",
        "train_features_JinAcc[:, 1, :] = np.max(normalized_JinAc_train, axis=1)\n",
        "train_features_JinAcc[:, 2, :] = np.min(normalized_JinAc_train, axis=1)\n",
        "train_features_JinAcc[:, 3, :] = np.sqrt(np.mean(normalized_JinAc_train**2, axis=1))\n",
        "train_features_JinAcc[:, 4, :] = np.sum(np.diff(np.sign(normalized_JinAc_train), axis=1) != 0, axis=1)\n",
        "train_features_JinAcc[:, 5, :] = np.std(normalized_JinAc_train, axis=1)\n",
        "\n",
        "# test\n",
        "test_features_JinAcc = np.zeros((testing_Examples, numof_features, test_JinAcc.shape[2]))\n",
        "\n",
        "# Calculate features for test_JinAcc\n",
        "test_features_JinAcc[:, 0, :] = np.mean(normalized_JinAcc_test, axis=1)\n",
        "test_features_JinAcc[:, 1, :] = np.max(normalized_JinAcc_test, axis=1)\n",
        "test_features_JinAcc[:, 2, :] = np.min(normalized_JinAcc_test, axis=1)\n",
        "test_features_JinAcc[:, 3, :] = np.sqrt(np.mean(normalized_JinAcc_test**2, axis=1))\n",
        "test_features_JinAcc[:, 4, :] = np.sum(np.diff(np.sign(normalized_JinAcc_test), axis=1) != 0, axis=1)\n",
        "test_features_JinAcc[:, 5, :] = np.std(normalized_JinAcc_test, axis=1)\n"
      ],
      "metadata": {
        "id": "zcWp2Vquu1AA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_features_JinGyro = np.zeros((training_Examples, numof_features, train_JinGyro.shape[2]))\n",
        "\n",
        "# Calculate features for train_JinGyro\n",
        "train_features_JinGyro[:, 0, :] = np.mean(normalized_JinGyro_train, axis=1)\n",
        "train_features_JinGyro[:, 1, :] = np.max(normalized_JinGyro_train, axis=1)\n",
        "train_features_JinGyro[:, 2, :] = np.min(normalized_JinGyro_train, axis=1)\n",
        "train_features_JinGyro[:, 3, :] = np.sqrt(np.mean(normalized_JinGyro_train**2, axis=1))\n",
        "train_features_JinGyro[:, 4, :] = np.sum(np.diff(np.sign(normalized_JinGyro_train), axis=1) != 0, axis=1)\n",
        "train_features_JinGyro[:, 5, :] = np.std(normalized_JinGyro_train, axis=1)\n",
        "\n",
        "# test\n",
        "test_features_JinGyro = np.zeros((testing_Examples, numof_features, test_JinGyro.shape[2]))\n",
        "\n",
        "# Calculate features for test_JinGyro\n",
        "test_features_JinGyro[:, 0, :] = np.mean(normalized_JinGyro_test, axis=1)\n",
        "test_features_JinGyro[:, 1, :] = np.max(normalized_JinGyro_test, axis=1)\n",
        "test_features_JinGyro[:, 2, :] = np.min(normalized_JinGyro_test, axis=1)\n",
        "test_features_JinGyro[:, 3, :] = np.sqrt(np.mean(normalized_JinGyro_test**2, axis=1))\n",
        "test_features_JinGyro[:, 4, :] = np.sum(np.diff(np.sign(normalized_JinGyro_test), axis=1) != 0, axis=1)\n",
        "test_features_JinGyro[:, 5, :] = np.std(normalized_JinGyro_test, axis=1)\n"
      ],
      "metadata": {
        "id": "cZN7vErhu30I"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating train_features_LintAcc array\n",
        "train_features_LintAcc = np.zeros((training_Examples, numof_features, train_LintAcc.shape[2]))\n",
        "\n",
        "# Calculate features for train_LintAcc\n",
        "train_features_LintAcc[:, 0, :] = np.mean(normalized_LintAcc_train, axis=1)\n",
        "train_features_LintAcc[:, 1, :] = np.max(normalized_LintAcc_train, axis=1)\n",
        "train_features_LintAcc[:, 2, :] = np.min(normalized_LintAcc_train, axis=1)\n",
        "train_features_LintAcc[:, 3, :] = np.sqrt(np.mean(normalized_LintAcc_train**2, axis=1))\n",
        "train_features_LintAcc[:, 4, :] = np.sum(np.diff(np.sign(normalized_LintAcc_train), axis=1) != 0, axis=1)\n",
        "train_features_LintAcc[:, 5, :] = np.std(normalized_LintAcc_train, axis=1)\n",
        "\n",
        "# test\n",
        "test_features_LintAcc = np.zeros((testing_Examples, numof_features, test_LintAcc.shape[2]))\n",
        "\n",
        "# Calculate features for test_LintAcc\n",
        "test_features_LintAcc[:, 0, :] = np.mean(normalized_LintAcc_test, axis=1)\n",
        "test_features_LintAcc[:, 1, :] = np.max(normalized_LintAcc_test, axis=1)\n",
        "test_features_LintAcc[:, 2, :] = np.min(normalized_LintAcc_test, axis=1)\n",
        "test_features_LintAcc[:, 3, :] = np.sqrt(np.mean(normalized_LintAcc_test**2, axis=1))\n",
        "test_features_LintAcc[:, 4, :] = np.sum(np.diff(np.sign(normalized_LintAcc_test), axis=1) != 0, axis=1)\n",
        "test_features_LintAcc[:, 5, :] = np.std(normalized_LintAcc_test, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "hXbJkjDmu-In"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_features_Magn = np.zeros((training_Examples, numof_features, train_Magn.shape[2]))\n",
        "\n",
        "# Calculate features for train_Magn\n",
        "train_features_Magn[:, 0, :] = np.mean(normalized_Magn_train, axis=1)\n",
        "train_features_Magn[:, 1, :] = np.max(normalized_Magn_train, axis=1)\n",
        "train_features_Magn[:, 2, :] = np.min(normalized_Magn_train, axis=1)\n",
        "train_features_Magn[:, 3, :] = np.sqrt(np.mean(normalized_Magn_train**2, axis=1))\n",
        "train_features_Magn[:, 4, :] = np.sum(np.diff(np.sign(normalized_Magn_train), axis=1) != 0, axis=1)\n",
        "train_features_Magn[:, 5, :] = np.std(normalized_Magn_train, axis=1)\n",
        "\n",
        "# test\n",
        "test_features_Magn = np.zeros((testing_Examples, numof_features, test_Magn.shape[2]))\n",
        "\n",
        "# Calculate features for test_Magn\n",
        "test_features_Magn[:, 0, :] = np.mean(normalized_Magn_test, axis=1)\n",
        "test_features_Magn[:, 1, :] = np.max(normalized_Magn_test, axis=1)\n",
        "test_features_Magn[:, 2, :] = np.min(normalized_Magn_test, axis=1)\n",
        "test_features_Magn[:, 3, :] = np.sqrt(np.mean(normalized_Magn_test**2, axis=1))\n",
        "test_features_Magn[:, 4, :] = np.sum(np.diff(np.sign(normalized_Magn_test), axis=1) != 0, axis=1)\n",
        "test_features_Magn[:, 5, :] = np.std(normalized_Magn_test, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "-xl-gU8Wu-2d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating train_features_MSAcc array\n",
        "train_features_MSAcc = np.zeros((training_Examples, numof_features, train_MSAcc.shape[2]))\n",
        "\n",
        "# Calculate features for train_MSAcc\n",
        "train_features_MSAcc[:, 0, :] = np.mean(normalized_MSAcc_train, axis=1)\n",
        "train_features_MSAcc[:, 1, :] = np.max(normalized_MSAcc_train, axis=1)\n",
        "train_features_MSAcc[:, 2, :] = np.min(normalized_MSAcc_train, axis=1)\n",
        "train_features_MSAcc[:, 3, :] = np.sqrt(np.mean(normalized_MSAcc_train**2, axis=1))\n",
        "train_features_MSAcc[:, 4, :] = np.sum(np.diff(np.sign(normalized_MSAcc_train), axis=1) != 0, axis=1)\n",
        "train_features_MSAcc[:, 5, :] = np.std(normalized_MSAcc_train, axis=1)\n",
        "\n",
        "# test\n",
        "test_features_MSAcc = np.zeros((testing_Examples, numof_features, test_MSAcc.shape[2]))\n",
        "\n",
        "# Calculate features for test_MSAcc\n",
        "test_features_MSAcc[:, 0, :] = np.mean(normalized_MSAcc_test, axis=1)\n",
        "test_features_MSAcc[:, 1, :] = np.max(normalized_MSAcc_test, axis=1)\n",
        "test_features_MSAcc[:, 2, :] = np.min(normalized_MSAcc_test, axis=1)\n",
        "test_features_MSAcc[:, 3, :] = np.sqrt(np.mean(normalized_MSAcc_test**2, axis=1))\n",
        "test_features_MSAcc[:, 4, :] = np.sum(np.diff(np.sign(normalized_MSAcc_test), axis=1) != 0, axis=1)\n",
        "test_features_MSAcc[:, 5, :] = np.std(normalized_MSAcc_test, axis=1)\n"
      ],
      "metadata": {
        "id": "kMggN2dovBzb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating train_features_MSGyro array\n",
        "train_features_MSGyro = np.zeros((training_Examples, numof_features, train_MSGyro.shape[2]))\n",
        "\n",
        "# Calculate features for train_MSGyro\n",
        "train_features_MSGyro[:, 0, :] = np.mean(normalized_MSGyro_train, axis=1)\n",
        "train_features_MSGyro[:, 1, :] = np.max(normalized_MSGyro_train, axis=1)\n",
        "train_features_MSGyro[:, 2, :] = np.min(normalized_MSGyro_train, axis=1)\n",
        "train_features_MSGyro[:, 3, :] = np.sqrt(np.mean(normalized_MSGyro_train**2, axis=1))\n",
        "train_features_MSGyro[:, 4, :] = np.sum(np.diff(np.sign(normalized_MSGyro_train), axis=1) != 0, axis=1)\n",
        "train_features_MSGyro[:, 5, :] = np.std(normalized_MSGyro_train, axis=1)\n",
        "\n",
        "# test\n",
        "test_features_MSGyro = np.zeros((testing_Examples, numof_features, test_MSGyro.shape[2]))\n",
        "\n",
        "# Calculate features for test_MSGyro\n",
        "test_features_MSGyro[:, 0, :] = np.mean(normalized_MSGyro_test, axis=1)\n",
        "test_features_MSGyro[:, 1, :] = np.max(normalized_MSGyro_test, axis=1)\n",
        "test_features_MSGyro[:, 2, :] = np.min(normalized_MSGyro_test, axis=1)\n",
        "test_features_MSGyro[:, 3, :] = np.sqrt(np.mean(normalized_MSGyro_test**2, axis=1))\n",
        "test_features_MSGyro[:, 4, :] = np.sum(np.diff(np.sign(normalized_MSGyro_test), axis=1) != 0, axis=1)\n",
        "test_features_MSGyro[:, 5, :] = np.std(normalized_MSGyro_test, axis=1)\n"
      ],
      "metadata": {
        "id": "XEd67l0uvE3x"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_features_Acc = train_features_Acc.reshape(training_Examples, -1)\n",
        "train_features_Gyro = train_features_Gyro.reshape(training_Examples, -1)\n",
        "train_features_Grav = train_features_Grav.reshape(training_Examples, -1)\n",
        "train_features_JinAcc = train_features_JinAcc.reshape(training_Examples, -1)\n",
        "train_features_JinGyro = train_features_JinGyro.reshape(training_Examples, -1)\n",
        "train_features_LintAcc = train_features_LintAcc.reshape(training_Examples, -1)\n",
        "train_features_Magn = train_features_Magn.reshape(training_Examples, -1)\n",
        "train_features_MSAcc = train_features_MSAcc.reshape(training_Examples, -1)\n",
        "train_features_MSGyro = train_features_MSGyro.reshape(training_Examples, -1)\n",
        "\n",
        "# test\n",
        "test_features_Acc = test_features_Acc.reshape(testing_Examples, -1)\n",
        "test_features_Gyro = test_features_Gyro.reshape(testing_Examples, -1)\n",
        "test_features_Grav = test_features_Grav.reshape(testing_Examples, -1)\n",
        "test_features_JinAcc = test_features_JinAcc.reshape(testing_Examples, -1)\n",
        "test_features_JinGyro = test_features_JinGyro.reshape(testing_Examples, -1)\n",
        "test_features_LintAcc = test_features_LintAcc.reshape(testing_Examples, -1)\n",
        "test_features_Magn = test_features_Magn.reshape(testing_Examples, -1)\n",
        "test_features_MSAcc = test_features_MSAcc.reshape(testing_Examples, -1)\n",
        "test_features_MSGyro = test_features_MSGyro.reshape(testing_Examples, -1)\n"
      ],
      "metadata": {
        "id": "cyN5-9Hr0zQX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenating Features"
      ],
      "metadata": {
        "id": "qzR0VDTjpz3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "concatenated_train_features = np.concatenate((train_features_Acc, train_features_Gyro, train_features_JinAcc,\n",
        "                                       train_features_Grav,train_features_JinGyro, train_features_LintAcc,\n",
        "                                       train_features_Magn,train_features_MSAcc, train_features_MSGyro), axis=1)\n",
        "print(concatenated_train_features.shape)\n",
        "\n",
        "# test\n",
        "concatenated_test_features = np.concatenate((test_features_Acc, test_features_Gyro, test_features_JinAcc,\n",
        "                                       test_features_Grav, test_features_JinGyro, test_features_LintAcc,\n",
        "                                       test_features_Magn, test_features_MSAcc, test_features_MSGyro), axis=1)\n",
        "print(concatenated_test_features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAdx3jKr3E-A",
        "outputId": "c22af176-e631-4333-9463-106b2ef43167"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2284, 162)\n",
            "(2288, 162)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Classifiers"
      ],
      "metadata": {
        "id": "lk2tdRTwqFTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = concatenated_train_features\n",
        "X_test = concatenated_test_features\n",
        "y_train = train_Labels\n",
        "y_test = test_Labels"
      ],
      "metadata": {
        "id": "v3T-oPmp_sTV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classifier"
      ],
      "metadata": {
        "id": "wHJq9hnfqsSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_predictions = rf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "rf_f1_score = f1_score(y_test, rf_predictions, average='weighted')\n",
        "rf_confusion_matrix = confusion_matrix(y_test, rf_predictions)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy*100,\"%\")\n",
        "print(\"Random Forest F1 Score:\", rf_f1_score)\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "print(rf_confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qdeJ_TE_O_U",
        "outputId": "4a2566ae-8ea2-4fe9-8f39-90b3eaac497d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 45.45454545454545 %\n",
            "Random Forest F1 Score: 0.4465083073173811\n",
            "Random Forest Confusion Matrix:\n",
            "[[32  1  0 ...  0  0  0]\n",
            " [ 0 39  1 ...  1  0  0]\n",
            " [ 0  7 10 ...  0  1  1]\n",
            " ...\n",
            " [ 0  3  0 ... 15  0  0]\n",
            " [ 0  0  0 ...  0 32  0]\n",
            " [ 0  0  0 ...  0  0 28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine (Classifier)"
      ],
      "metadata": {
        "id": "LMkfM0EbqxDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Classifier\n",
        "classfier = SVC(C=1.0, kernel='linear')\n",
        "classfier.fit(X_train,y_train)\n",
        "estimatedLabels = classfier.predict(X_test)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test,estimatedLabels)\n",
        "svm_f1_score = f1_score(y_test,estimatedLabels,average='weighted')\n",
        "svm_confusion_matrix = confusion_matrix(y_test,estimatedLabels)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy*100,\"%\")\n",
        "print(\"SVM F1 Score:\", svm_f1_score)\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(svm_confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVIDC32HuVRL",
        "outputId": "5a9e6321-ef13-4254-fb3f-a4bf197f5aa8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 20.06118881118881 %\n",
            "SVM F1 Score: 0.15737104875619132\n",
            "SVM Confusion Matrix:\n",
            "[[16  0  0 ...  0  0  0]\n",
            " [ 0 30  0 ...  0  0  0]\n",
            " [ 0  9  0 ...  0  0  0]\n",
            " ...\n",
            " [ 0  2  1 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Neural Network"
      ],
      "metadata": {
        "id": "GZ_U6IJcq36w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN Classifier\n",
        "dnn = MLPClassifier(hidden_layer_sizes=(256, 128, 64), activation='relu',learning_rate_init=0.03,max_iter=2000)\n",
        "dnn.fit(X_train, y_train)\n",
        "dnn_predictions = dnn.predict(X_test)\n",
        "dnn_accuracy = accuracy_score(y_test, dnn_predictions)\n",
        "dnn_f1_score = f1_score(y_test, dnn_predictions, average='weighted')\n",
        "dnn_confusion_matrix = confusion_matrix(y_test, dnn_predictions)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"DNN Accuracy:\", dnn_accuracy*100)\n",
        "print(\"DNN F1 Score:\", dnn_f1_score)\n",
        "print(\"DNN Confusion Matrix:\")\n",
        "print(dnn_confusion_matrix)\n"
      ],
      "metadata": {
        "id": "Pbh8J1lR4e3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e74e5df-e870-481a-ca66-66c96721b0fa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN Accuracy: 18.96853146853147\n",
            "DNN F1 Score: 0.1549968198059873\n",
            "DNN Confusion Matrix:\n",
            "[[12  1  0 ...  0  1  0]\n",
            " [ 0  5  1 ...  2  0  0]\n",
            " [ 0  2  0 ...  2  1  0]\n",
            " ...\n",
            " [ 0  0  0 ...  1  0  0]\n",
            " [ 0  0  0 ...  0  2  0]\n",
            " [ 0  0  0 ...  1  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# Get the predicted probabilities for each class\n",
        "dnn_probabilities = dnn.predict_proba(X_test)\n",
        "\n",
        "# Calculate the average precision for each class\n",
        "ap_scores = []\n",
        "for class_idx in range(55):\n",
        "    y_true_class = (y_test == class_idx).astype(int)\n",
        "    y_score_class = dnn_probabilities[:, class_idx]\n",
        "    ap = average_precision_score(y_true_class, y_score_class)\n",
        "    ap_scores.append(ap)\n",
        "\n",
        "# Calculate the mean average precision\n",
        "map_score = sum(ap_scores) / len(ap_scores)\n",
        "\n",
        "print(\"Mean Average Precision (MAP):\", map_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V1LFxgrFZqB",
        "outputId": "f3b9fad8-0031-487f-b1d2-2886d6a90392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Precision (mAP): 0.15073853297142972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbours"
      ],
      "metadata": {
        "id": "QcFtjb1uq805"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Classifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "knn_predictions = knn.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "knn_f1_score = f1_score(y_test, knn_predictions, average='weighted')\n",
        "knn_confusion_matrix = confusion_matrix(y_test, knn_predictions)\n",
        "print(\"KNN Accuracy:\", knn_accuracy*100, \"%\")\n",
        "print(\"KNN F1 Score:\", knn_f1_score)\n",
        "print(\"KNN Confusion Matrix:\")\n",
        "print(knn_confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arDBjMZf_TBf",
        "outputId": "ed45d2f0-c6ac-4abc-d394-fca239f2ecc6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 16.695804195804197 %\n",
            "KNN F1 Score: 0.1522517275316911\n",
            "KNN Confusion Matrix:\n",
            "[[19  2  0 ...  0  0  0]\n",
            " [ 0 22  4 ...  0  0  0]\n",
            " [ 1  7  0 ...  1  0  0]\n",
            " ...\n",
            " [ 0  5  2 ...  4  0  0]\n",
            " [ 2  6  2 ...  2  0  0]\n",
            " [ 0  1  3 ...  1  0  0]]\n"
          ]
        }
      ]
    }
  ]
}